{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fccb559e",
   "metadata": {},
   "source": [
    "# BeaverTails-Evaluation dataset [beaver_tails_dataset.json]\n",
    "- Load via Hugging Face datasets: https://huggingface.co/datasets/PKU-Alignment/BeaverTails-Evaluation\n",
    "- The official split contains 700 samples across 14 categories.\n",
    "- Save locally without any sampling to ./my_dataset/beaver_tails_dataset.json and also use save_to_disk for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7bb2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "ds = load_dataset(\"PKU-Alignment/BeaverTails-Evaluation\")\n",
    "\n",
    "# Save the full dataset to a local directory (relative path, obfuscated for GitHub)\n",
    "DATA_DIR = Path(\"./my_dataset\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "local_directory = DATA_DIR / \"beaver_tails_dataset\"\n",
    "ds.save_to_disk(str(local_directory))\n",
    "\n",
    "print(f\"Dataset saved to {local_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daa7612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "ds = load_dataset('PKU-Alignment/BeaverTails-Evaluation')\n",
    "\n",
    "# Save split to JSON (relative path for GitHub)\n",
    "DATA_DIR = Path(\"./my_dataset\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "json_file_path = DATA_DIR / 'beaver_tails_dataset.json'\n",
    "\n",
    "# Convert the dataset to JSON and save it\n",
    "ds['test'].to_json(str(json_file_path))\n",
    "\n",
    "print(f\"Dataset saved as JSON to {json_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c2afdb",
   "metadata": {},
   "source": [
    "# HarmfulQA dataset [harmfulqa.jsonl]\n",
    "- Load declare-lab/HarmfulQA: https://huggingface.co/datasets/declare-lab/HarmfulQA\n",
    "- 1,960 harmful questions across 10 topics (with subtopics).\n",
    "- Randomly select 700 samples balanced across topics (70 per topic; subtopics are not balanced).\n",
    "- Extract question/topic/subtopic and save to ./my_dataset/harmfulqa.jsonl.\n",
    "- Use random.seed(42) for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfca4017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the HarmfulQA dataset\n",
    "ds = load_dataset(\"declare-lab/HarmfulQA\")\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "def balanced_random_sample(dataset, output_file_path, num_samples=700):\n",
    "    \"\"\"\n",
    "    Sample an approximately balanced subset by 'topic' and write it as an intermediate JSON array.\n",
    "    The final JSONL with selected fields will be generated in the next step.\n",
    "    \"\"\"\n",
    "    topics = dataset['train'].unique('topic')\n",
    "    num_topics = len(topics)\n",
    "    if num_topics == 0:\n",
    "        raise ValueError(\"No topics found in HarmfulQA train split.\")\n",
    "\n",
    "    samples_per_topic = max(1, num_samples // num_topics)\n",
    "    sampled_data = []\n",
    "\n",
    "    for topic in topics:\n",
    "        # Filter data by topic, convert to a list of dicts\n",
    "        topic_data = list(dataset['train'].filter(lambda x: x['topic'] == topic))\n",
    "        k = min(samples_per_topic, len(topic_data))\n",
    "        if k > 0:\n",
    "            sampled_data.extend(random.sample(topic_data, k))\n",
    "\n",
    "    # Write the sampled data to JSON\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "        json.dump(sampled_data, output_file, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return sampled_data\n",
    "\n",
    "# Example usage (relative, obfuscated path):\n",
    "DATA_DIR = Path(\"./my_dataset\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "output_file_path = DATA_DIR / 'harmfulqa_balanced_sample.json'\n",
    "sampled_data = balanced_random_sample(ds, str(output_file_path))\n",
    "\n",
    "print(f\"Balanced sample saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a581a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def convert_to_jsonl(input_json_path, output_jsonl_path):\n",
    "    \"\"\"\n",
    "    Convert the intermediate JSON array from balanced_random_sample into JSONL.\n",
    "    Each line contains: {\"topic\": \"...\", \"subtopic\": \"...\", \"question\": \"...\"}\n",
    "    \"\"\"\n",
    "    with open(input_json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    with open(output_jsonl_path, 'w', encoding='utf-8') as outfile:\n",
    "        for sample in data:\n",
    "            topic = sample.get('topic', 'unknown_topic')\n",
    "            subtopic = sample.get('subtopic', 'unknown_subtopic')\n",
    "            question = sample.get('question', 'unknown_question')\n",
    "            json_line = json.dumps({\n",
    "                \"topic\": topic,\n",
    "                \"subtopic\": subtopic,\n",
    "                \"question\": question\n",
    "            }, ensure_ascii=False)\n",
    "            outfile.write(json_line + '\\n')\n",
    "\n",
    "    print(f\"JSONL file saved to {output_jsonl_path}\")\n",
    "    return output_jsonl_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a0647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to JSONL\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"./my_dataset\")\n",
    "output_json_path = DATA_DIR / 'harmfulqa_balanced_sample.json'\n",
    "output_jsonl_path = DATA_DIR / 'harmfulqa.jsonl'\n",
    "convert_to_jsonl(str(output_json_path), str(output_jsonl_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b234168",
   "metadata": {},
   "source": [
    "# TruthfulQA dataset [TruthfulQA.jsonl]\n",
    "- Download CSV from the original repository (790 samples):\n",
    "  https://github.com/sylinrl/TruthfulQA/blob/main/TruthfulQA.csv\n",
    "- Convert to JSONL for easier downstream processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f106fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Input/Output paths (relative, for GitHub)\n",
    "DATA_DIR = Path(\"./my_dataset\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "csv_file_path = DATA_DIR / 'TruthfulQA.csv'\n",
    "jsonl_file_path = DATA_DIR / 'TruthfulQA.jsonl'\n",
    "\n",
    "with open(csv_file_path, 'r', encoding='utf-8') as csv_file:\n",
    "    reader = csv.DictReader(csv_file)\n",
    "    with open(jsonl_file_path, 'w', encoding='utf-8') as jsonl_file:\n",
    "        for row in reader:\n",
    "            jsonl_file.write(json.dumps(row, ensure_ascii=False) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e75c5c3",
   "metadata": {},
   "source": [
    "# DialogSum dataset [dialogsum_test.jsonl]\n",
    "- Use the test split provided by the authors (500 samples):\n",
    "  https://github.com/cylnlp/dialogsum/blob/main/DialogSum_Data/dialogsum.test.jsonl\n",
    "- Place it under: ./my_dataset/dialogsum_test.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffaee1b",
   "metadata": {},
   "source": [
    "# EmpatheticDialogues (Empathy) [empathy_test.jsonl]\n",
    "- Original repository: https://github.com/facebookresearch/EmpatheticDialogues\n",
    "- Download data: wget https://dl.fbaipublicfiles.com/parlai/empatheticdialogues/empatheticdialogues.tar.gz\n",
    "- Use the test split; select 16 negative emotion categories; deduplicate prompts; filter out too-short texts; sample up to 40 per category (seed=42).\n",
    "- Save the final 640 examples to ./my_dataset/empathy_test.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1cda00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Read the CSV (handle quoting/escaping issues)\n",
    "ROOT = Path(\".\")\n",
    "DATA_DIR = ROOT / \"my_dataset\"\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(\n",
    "    ROOT / 'empatheticdialogues' / 'test.csv',\n",
    "    quotechar='\"',\n",
    "    escapechar='\\\\',\n",
    "    on_bad_lines='skip'\n",
    ")\n",
    "\n",
    "# Target emotion categories (16)\n",
    "emotions = [\"angry\", \"confident\", \"embarrassed\", \"proud\", \"sad\", \"lonely\", \"terrified\", \"disgusted\", \"devastated\", \"annoyed\", \"ashamed\", \"anxious\", \"jealous\", \"disappointed\", \"afraid\", \"guilty\"]\n",
    "\n",
    "# Filter rows and drop duplicate prompts\n",
    "filtered_df = df[df['context'].isin(emotions)].drop_duplicates(subset=['prompt'])\n",
    "\n",
    "# Emit category/prompt pairs as JSONL\n",
    "out_jsonl = DATA_DIR / 'empathy.jsonl'\n",
    "with open(out_jsonl, 'w', encoding='utf-8') as f:\n",
    "    for _, row in filtered_df.iterrows():\n",
    "        obj = {'category': row['context'], 'prompt': row['prompt']}\n",
    "        f.write(json.dumps(obj, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(f\"Wrote {len(filtered_df)} lines to {out_jsonl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56d2c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# Reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "emotions = [\"angry\", \"confident\", \"embarrassed\", \"proud\", \"sad\", \"lonely\", \"terrified\",\n",
    "            \"disgusted\", \"devastated\", \"annoyed\", \"ashamed\", \"anxious\", \"jealous\",\n",
    "            \"disappointed\", \"afraid\", \"guilty\"]\n",
    "\n",
    "DATA_DIR = Path(\"./my_dataset\")\n",
    "input_path = DATA_DIR / 'empathy.jsonl'\n",
    "with open(input_path, 'r', encoding='utf-8') as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "# Clean and filter\n",
    "cleaned = [\n",
    "    {\"category\": d.get(\"category\"), \"prompt\": d.get(\"prompt\", \"\").replace(\"_comma_\", \",\")}\n",
    "    for d in data\n",
    "    if d.get(\"category\") in emotions and len(d.get(\"prompt\", \"\")) >= 40\n",
    "]\n",
    "\n",
    "# Group and sample\n",
    "by_cat = {emo: [] for emo in emotions}\n",
    "for item in cleaned:\n",
    "    by_cat[item[\"category\"]].append(item)\n",
    "final_data = [\n",
    "    s\n",
    "    for emo in emotions\n",
    "    for s in random.sample(by_cat[emo], min(40, len(by_cat[emo])))\n",
    "]\n",
    "\n",
    "# Write output\n",
    "output_path = DATA_DIR / 'empathy_test.jsonl'\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    for item in final_data:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(f\"Data processing complete, written to {output_path}, total samples: {len(final_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e202b9",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Dataset | Classes | Samples | Path |\n",
    "| --- | --- | --- | --- |\n",
    "| empathy_test.jsonl | 16 | 640 | ./my_dataset/empathy_test.jsonl |\n",
    "| dialogsum_test.jsonl | - | 500 | ./my_dataset/dialogsum_test.jsonl |\n",
    "| TruthfulQA.jsonl | - | 790 | ./my_dataset/TruthfulQA.jsonl |\n",
    "| beaver_tails_dataset.json | 14 | 700 | ./my_dataset/beaver_tails_dataset.json |\n",
    "| harmfulqa.jsonl | 10 | 700 | ./my_dataset/harmfulqa.jsonl |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62ba5f5",
   "metadata": {},
   "source": [
    "# Shuffle dataset order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1254ea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "def shuffle_jsonl(input_path, output_path, seed=42):\n",
    "    \"\"\"Shuffle lines of a JSONL file deterministically by seed.\"\"\"\n",
    "    random.seed(seed)\n",
    "    input_path = Path(input_path)\n",
    "    output_path = Path(output_path)\n",
    "    lines = input_path.read_text(encoding='utf-8').splitlines()\n",
    "    random.shuffle(lines)\n",
    "    output_path.write_text(('\\n'.join(lines) + ('\\n' if lines else '')), encoding='utf-8')\n",
    "    print(f\"Shuffled dataset written to {output_path}, total {len(lines)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e7b2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: shuffle empathy_test.jsonl in-place\n",
    "shuffle_jsonl(\n",
    "    input_path=\"./my_dataset/empathy_test.jsonl\",\n",
    "    output_path=\"./my_dataset/empathy_test.jsonl\",\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fcc578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: shuffle harmfulqa.jsonl in-place\n",
    "shuffle_jsonl(\n",
    "    input_path=\"./my_dataset/harmfulqa.jsonl\",\n",
    "    output_path=\"./my_dataset/harmfulqa.jsonl\",\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b44c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the BeaverTails dataset and print the split info\n",
    "dataset = load_dataset('PKU-Alignment/BeaverTails-Evaluation')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a00ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snippet for papers/docs\n",
    "\n",
    "import json\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "emotions = [\"angry\", \"confident\", \"embarrassed\", \"proud\", \"sad\", \"lonely\", \"terrified\",\n",
    "            \"disgusted\", \"devastated\", \"annoyed\", \"ashamed\", \"anxious\", \"jealous\",\n",
    "            \"disappointed\", \"afraid\", \"guilty\"]\n",
    "\n",
    "# Read the original jsonl file\n",
    "input_path = \"\"  # your path here\n",
    "with open(input_path, \"r\", encoding='utf-8') as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "# Preprocess: replace _comma_ and filter out short texts\n",
    "cleaned_data = []\n",
    "for item in data:\n",
    "    category = item[\"category\"]\n",
    "    prompt = item[\"prompt\"].replace(\"_comma_\", \",\")\n",
    "    if category in emotions and len(prompt) >= 40:\n",
    "        cleaned_data.append({\"category\": category, \"prompt\": prompt})\n",
    "\n",
    "# Sample up to 40 items per emotion category\n",
    "samples_per_emotion = defaultdict(list)\n",
    "for item in cleaned_data:\n",
    "    samples_per_emotion[item[\"category\"]].append(item)\n",
    "\n",
    "# Randomly sample 40 items per category\n",
    "final_data = []\n",
    "for emotion in emotions:\n",
    "    samples = samples_per_emotion[emotion]\n",
    "    if len(samples) >= 40:\n",
    "        final_data.extend(random.sample(samples, 40))\n",
    "    else:\n",
    "        print(f\"Not enough samples for emotion '{emotion}': only {len(samples)}; keeping all.\")\n",
    "\n",
    "# Shuffle the order of the data randomly\n",
    "random.shuffle(final_data)\n",
    "\n",
    "# Write to new file\n",
    "output_path = \"\"  # your path here\n",
    "with open(output_path, \"w\", encoding='utf-8') as f:\n",
    "    for item in final_data:\n",
    "        json.dump(item, f, ensure_ascii=False)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"Data processing complete. Written to {output_path}. Total samples: {len(final_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7395fc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standalone snippet for HarmfulQA balanced sampling\n",
    "\n",
    "import random\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the HarmfulQA dataset\n",
    "ds = load_dataset(\"declare-lab/HarmfulQA\")\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "def balanced_random_sample(dataset, output_file_path, num_samples=700):\n",
    "    # List unique topics\n",
    "    topics = dataset['train'].unique('topic')\n",
    "    num_topics = len(topics)\n",
    "    if num_topics == 0:\n",
    "        raise ValueError(\"No topics found in HarmfulQA train split.\")\n",
    "\n",
    "    # Calculate target per topic\n",
    "    samples_per_topic = max(1, num_samples // num_topics)\n",
    "\n",
    "    sampled_data = []\n",
    "    for topic in topics:\n",
    "        topic_data = list(dataset['train'].filter(lambda x: x['topic'] == topic))\n",
    "        k = min(samples_per_topic, len(topic_data))\n",
    "        if k > 0:\n",
    "            sampled_data.extend(random.sample(topic_data, k))\n",
    "\n",
    "    # Write the sampled data to the output file in JSON format\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "        json.dump(sampled_data, output_file, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return sampled_data\n",
    "\n",
    "# Example usage:\n",
    "output_file_path = './my_dataset/harmfulqa_balanced_sample.json'  # your path here\n",
    "sampled_data = balanced_random_sample(ds, output_file_path)\n",
    "\n",
    "print(f\"Balanced sample saved to {output_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
